<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Jiahong Ouyang's Homepage</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<section id="header">
				<header>
					<span class="image avatar"><img src="images/me.jpg" alt="" /></span>
					<h1 id="logo"><a href="#">Jiahong Ouyang</a></h1>
					<p></p>
				</header>
				<nav id="nav">
					<ul>
						<li><a href="#one" class="active">About</a></li>
						<li><a href="#two">Recent Work</a></li>
						<li><a href="#three">Publications</a></li>
						<li><a href="#four">Honors & Awards</a></li>
						<li><a href="#five">Professional Services</a></li>
						<li><a href="#six">Others</a></li>
						<li><a href="#seven">Fun Facts</a></li>
					</ul>
				</nav>
				<!-- <footer>
					<ul class="icons">
						<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
						<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
						<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
						<li><a href="#" class="icon brands fa-github"><span class="label">Github</span></a></li>
						<li><a href="#" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
					</ul>
				</footer> -->
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">

						<!-- One -->
							<section id="one">
								<div class="image main" data-position="center">
									<img src="images/stanford_bg.jpg" alt="" />
								</div>
								<div class="container">
									<header class="major">
										<h2><font color="#6F9FD8">Jiahong Ouyang</font></h2>
									</header>
									<p>I’m a 3-rd year Ph.D. candidate at Department of Electrical Engineering, Stanford University. I am co-advised by <a href="https://profiles.stanford.edu/greg-zaharchuk"><font color="#6F9FD8">Dr. Greg Zaharchuk</font></a> and <a href="http://cnslab.stanford.edu/personal/kilian-pohl"><font color="#6F9FD8">Dr. Kilian Pohl</font></a>. My main research interests are the intersection of machine learning, medical imaging, and medical image analysis, especially on multi-modal and longitudinal analysis for neuroimaging. <br /><br /> Before starting my Ph.D., I received my B.S. in 2017 from Tsinghua University and a M.S. in Robotics in 2018 from Carnegie Mellon University, where I worked with <a href="https://www.ri.cmu.edu/ri-faculty/john-galeotti/"><font color="#6F9FD8">Dr. John Galeotti</font></a> on tissue interface segmentation on OCT images. <br /> <br /> Contact: jiahongo -at- stanford dot edu <br /> <a href="https://scholar.google.com/citations?user=B_D7cCAAAAAJ&hl=en"><font color="#6F9FD8">[Google Scholar]</font></a> <a href="https://github.com/ouyangjiahong"><font color="#6F9FD8">[Github]</font></a>  <a href="https://www.linkedin.com/in/jiahong-ouyang-486bab126/"><font color="#6F9FD8">[Linkedin]</font></a> </p>
								</div>
							</section>

							<section id="news">
								<div class="container">
									<h3>News</h3>
									<div class="features">
										<article>
											<p>
												<ul>
													<li> [May 2022] We have one <a href="https://jnis.bmj.com/content/neurintsurg/early/2022/04/27/neurintsurg-2021-018638.full.pdf"><font color="#6F9FD8">paper</font></a> accepted by Journal of NeuroInterventional Surgery. <br /></li>
													<li> [April 2022] We have one <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9754514"><font color="#6F9FD8">paper</font></a> accepted by IEEE Transactions of Medical Imaging. <br /></li>
													<li> [April 2022] I'm going to do summer internship at Philips Research at Cambridge, MA.  <br /></li>
												</ul>
											</p>
										</article>
									</div>
								</div>
							</section>

						<!-- Three -->
							<section id="two">
								<div class="container">
									<h3>Recent Works</h3>
									<div class="features">
										<article>
											<h4>Longitudinal Analysis</h4>
											<a href="#" class="image"><img src="images/longitudinal.png" alt="" style="width:90%;margin:0 5%"/></a>
											<div class="inner">
												<p>Longitudinal MRIs enable noninvasive tracking of the gradual deterioration of brain structure and function caused by neurological diseases and environmental influences over time. We first proposed a CNN+RNN based framework with a longitudinal pooling layer and a consistency loss function to achieve longitudinally and clinically consistent diagnosis prediction. <a href="https://pubmed.ncbi.nlm.nih.gov/33270567/"><font color="#6F9FD8">[paper]</font></a><a href="https://github.com/ouyangjiahong/longitudinal-pooling"><font color="#6F9FD8">[code]</font></a><br><br>
												However, the longitudinal analysis is complicated by the complex covariance structure characterizing a mixture of time-varying and static effects across visits. It generally requires a large number of ground-truth labels, which are often missing or expensive to obtain. To mitigate this challenge, <a href="https://www.sciencedirect.com/science/article/pii/S1361841521000979"><font color="#6F9FD8">LSSL</font></a>, a longitudinal self-supervised learning method, was proposed by our group to model the brain aging by a linear direction in the latent space. <br><br> But it has two main drawbacks: (1) a linear direction might not have the capacity to model complex longitudinal changes; (2) it can only model diseases/disorders that can be considered accelerated or daccelarated aging. To resolve the first probelm, we further proposed to regularize a smooth trajectory vector field in the latent space. <a href="https://link.springer.com/chapter/10.1007/978-3-030-87196-3_8"><font color="#6F9FD8">[paper]</font></a><a href="https://github.com/ouyangjiahong/longitudinal-neighbourhood-embedding"><font color="#6F9FD8">[code]</font></a> To solve the second problem, we proposed to disentangle a disease progression from the normal brain aging. <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9754514"><font color="#6F9FD8">[paper]</font></a> <a href="https://github.com/ouyangjiahong/longitudinal-direction-disentangle"><font color="#6F9FD8">[code]</font></a> </p>
											</div>
										</article>
										<article>
											<h4>Multi-Modal Analysis</h4>
											<a href="#" class="image"><img src="images/multi-modal.png" alt="" style="width:70%;margin:0 15%"/></a>
											<div class="inner">
												<p>Multi-modal MR images are widely used in neuroimaging applications to provide complementary information about the brain structures. Multi-modal deep learning analysis can be benefit from explicitly disentangling anatomical (shape) and modality (appearance) representations. We proposed a novel margin-based similarity loss and a modified conditional convolution to enable efficient fully disentanglement. We further introduced a fusion function to obtain a set of modality-invariant features for downstream tasks. <a href="https://arxiv.org/abs/2102.11456"><font color="#6F9FD8">[paper]</font></a> <a href="https://github.com/ouyangjiahong/representation-disentanglement"><font color="#6F9FD8">[code]</font></a> <a href="http://ipmi2021.org/papers/83/"><font color="#6F9FD8">[talk]</font></a></p>
											</div>
										</article>
										<article>
											<h4>Low-dose/Zero-dose PET Reconstruction</h4>
											<a href="#" class="image"><img src="images/lowdose.png" alt=""  style="width:55%;margin:0 20%"/></a>
											<div class="inner">
												<p>Positron emission tomography (PET) is a widely used imaging technique in many clinical applications including tumor detection and neurological disorder diagnosis. To obtain high-quality images, the amount of injected radiotracer in current protocols leads to the risk of radiation exposure in scanned subjects. Decreasing this injected dose will lead to low quality images that can further affecting the disease diagnosis. We propose one of the pioneer work that synthesizes high quality and pathologically accurate amyloid PET images solely from 1% ultra-low-dose PET using cGAN with task-specific perceptual loss. <a href="https://pubmed.ncbi.nlm.nih.gov/31131901/"><font color="#6F9FD8">[paper]</font></a> We further attempt to push the boundary to zero-dose PET, i.e., using widely available and non-invasive MRI to synthesize PET images. We propose a U-Net based model with symmetry-aware spatial-wise attention module and channel attention-wise module to accurately capture the abnormality. <a href="http://www.cse.cuhk.edu.hk/~qdou/public/medneurips2020/21_NIPS_2020_Med_Img_Zerodose_final.pdf"><font color="#6F9FD8">[abstract]</font></a> </p>
											</div>
										</article>
									</div>
								</div>
							</section>

							<section id="three">
								<div class="container">
									<h3>Publications</h3>
									<div class="features">
										<article>
											<h4>Journals</h4>
											<div class="inner">
												<p> <b><a href="https://jnis.bmj.com/content/neurintsurg/early/2022/04/27/neurintsurg-2021-018638.full.pdf"><font color="#6F9FD8">Automated Detection of Arterial Landmarks and Vascular Occlusions in Patients with Acute Stroke Receiving Digital Subtraction Angiography Using Deep Learning</font></a> </b> <br /> J. Khankari, Y. Yu, <b>J. Ouyang</b>, R. Hussein, H. Do, J. Heit, G. Zaharchuk <br /> Journal of NeuroInterventional Surgery, 2022 <br /><br />
													<b><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9754514"><font color="#6F9FD8">Disentangling Normal Aging from Severity of Disease via Weak Supervision on Longitudinal MRI</font></a> </b> <br /> <b>J. Ouyang</b>, Q. Zhao, E. Adeli, G. Zaharchuk, K. Pohl <br /> IEEE Transactions on Medical Imaging, 2022 <a href="https://github.com/ouyangjiahong/longitudinal-direction-disentangle"><font color="#6F9FD8">[code]</font></a> <br /><br />
														<!-- <b><a href="https://www.ahajournals.org/doi/abs/10.1161/str.53.suppl_1.8"><font color="#6F9FD8">Hypoperfusion Lesion And Target Mismatch Prediction In Acute Ischemic Stroke From Baseline Mr Diffusion Imaging Using A 3d Convolutional Neural Network</font></a> </b> <br /> Y. Yu, E. Gong, <b>J. Ouyang</b>, S. Christensen, F. Scalzo, D. Liebeskind, M. Lansberg, G. Albers, G. Zaharchuk <br /> Stroke, 2022 <br /><br /> -->
													<b><a href="https://www.sciencedirect.com/science/article/pii/S2352396421004060"><font color="#6F9FD8">Deep Learning Evaluation of Biomarkers from Echocardiogram Videos</font></a> </b> <br /> J. Hughes, N. Yuan, B. He, <b>J. Ouyang</b>, ..., D. Ouyang, J. Zou <br /> EBioMedicine, 2021 <br /><br />
													<b><a href="http://www.ajnr.org/content/ajnr/early/2021/03/25/ajnr.A7081.full.pdf"><font color="#6F9FD8">Tissue at Risk and Ischemic Core Estimation Using Deep Learning in Acute Stroke</font></a> </b> <br /> Y. Yu, Y. Xie, T. Thamm, E. Gong, <b>J. Ouyang</b>, S. Christensen, M. Marks, M. Lansberg, G. Albers, G. Zaharchuk <br /> American Journal of Neuroradiology, 2021 <b> (Annual Lucien Levy Best Research Article Award) </b> <br /><br />
													<b><a href="https://pubmed.ncbi.nlm.nih.gov/33270567/"><font color="#6F9FD8">Longitudinal Pooling & Consistency Regularization to Model Disease Progression from MRIs</font></a> </b> <br /> <b>J. Ouyang</b>, Q. Zhao, E. Sullivan, A. Pfefferbaum, S. Tapert, E. Adeli, K. Pohl <br /> Journal of Biomedical and Health Informatics (JBHI), 2020 <a href="https://github.com/ouyangjiahong/longitudinal-pooling"><font color="#6F9FD8">[code]</font></a> <br /><br />
													<b><a href="https://link.springer.com/article/10.1007/s00259-020-04897-6"><font color="#6F9FD8">Generalization of Deep Learning Models for Ultra-low-count Amyloid PET/MRI Using Transfer Learning</font></a> </b> <br /> K. Chen, M. Schurer, <b>J. Ouyang</b>, M. Koran, G. Davidzon, E. Mormino, S. Tieport, K. Hoffmann, O. Sabri, G. Zaharchuk, H. Barthel <br /> European Journal of Nuclear Medicine and Molecular Imaging, 2020 <br /> <br />
													<b><a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2762679"><font color="#6F9FD8">Use of Deep Learning to Predict Final Ischemic Stroke Lesions From Initial Magnetic Resonance Imaging</font></a> </b> <br /> Y. Yu, Y. Xie, T. Thamm, E. Gong, <b>J. Ouyang</b>, C. Huang, S. Christensen, M. Marks, M. Lansberg, G. Albers, G. Zaharchuk <br /> Journal of the American Medical Association (JAMA) Network Open, 2020 <br /> <br />
													<b><a href="https://www.osapublishing.org/DirectPDFAccess/10159B1F-CB05-AB8D-AFD7A42CBCE97666_420799/boe-10-10-5291.pdf?da=1&id=420799&seq=0&mobile=no"><font color="#6F9FD8">Accurate Tissue Interface Segmentation via Adversarial Pre-segmentation of Anterior Segment OCT Images</font></a> </b> <br /> <b>J. Ouyang</b>, T. Mathai, J. Galeotti <br /> Biomedical Optics Express, 2019 <br /> <br />
													<b><a href="https://pubmed.ncbi.nlm.nih.gov/31131901/"><font color="#6F9FD8">Ultra-low-dose Amyloid PET Reconstruction by Generative Adversarial Network with Feature Matching and Task-specific Perceptual Loss</font></a> </b> <br /> <b>J. Ouyang</b>, E. Gong, K. Chen, J. Pauly, G. Zaharchuk <br /> Medical Physics, 2019 <br /> <br />
												</p>
											</div>
										</article>
										<article>
											<h4>Conferences</h4>
											<div class="inner">
												<p> <b><a href="https://link.springer.com/chapter/10.1007/978-3-030-87196-3_8"><font color="#6F9FD8">Self-Supervised Longitudinal Neighbourhood Embedding</font></a> </b> <br /> <b>J. Ouyang</b>, Q. Zhao, E. Adeli, E. Sullivan, A. Pfefferbaum, G. Zaharchuk, K. Pohl <br /> Medical Image Computing and Computer Assisted Intervention (MICCAI) 2021 <b> (Oral Presentation, Young Scientist Award Shortlisted, 10 over 1630 papers)</b> <a href="https://github.com/ouyangjiahong/longitudinal-neighbourhood-embedding"><font color="#6F9FD8">[code]</font></a><br /> <br />
													<b><a href="https://link.springer.com/chapter/10.1007/978-3-030-78191-0_25"><font color="#6F9FD8">Representation Disentanglement for Multi-modal MR Analysis</font></a> </b> <br /> <b>J. Ouyang</b>, E. Adeli, K. Pohl, Q. Zhao, G. Zaharchuk <br /> Information Processing for Medical Imaging (IPMI) 2021  <b> (Oral Presentation)</b> <a href="https://github.com/ouyangjiahong/representation-disentanglement"><font color="#6F9FD8">[code]</font></a><a href="http://ipmi2021.org/papers/83/"><font color="#6F9FD8">[talk]</font></a> <br /> <br />
													<b><a href="https://www.spiedigitallibrary.org/proceedings/Download?fullDOI=10.1117/12.2548350"><font color="#6F9FD8">Ultra-low-dose 18F-FDG Brain PET/MR Denoising Using Deep Learning and Multi-contrast Information</font></a> </b> <br /> J. Xu, E. Gong, <b>J. Ouyang</b>, J. Pauly, G. Zaharchuk, S. Han <br /> Medical Imaging 2020: Image Processing  <b> (Oral Presentation)</b> <br /> <br />
													<b><a href="https://link.springer.com/chapter/10.1007/978-3-030-33843-5_18"><font color="#6F9FD8">Task-GAN: Improving Generative Adversarial Network for Image Reconstruction</font></a> </b> <br /> <b>J. Ouyang</b>, G. Wang, E. Gong, K. Chen, J. Pauly, G. Zaharchuk <br /> MICCAI Machine Learning for Medical Image Reconstruction Workshop (MLMIR) 2019 <br /> <br />
													<b><a href="https://ieeexplore.ieee.org/iel7/8263072/8272674/08272707.pdf"><font color="#6F9FD8">Fingerprint Pose Estimation based on Faster R-CNN </font></a></b> <br /> <b>J. Ouyang</b>, J. Feng, J. Lu, Z. Guo, J. Zhou <br /> International Joint Conference on Biometrics (IJCB) 2017 <b> (Oral Presentation, Best Student Paper Award Runner-Up)</b>
												</p>
											</div>
										</article>
									</div>
								</div>
							</section>

							<section id="four">
								<div class="container">
									<h3>Honors & Awards</h3>
									<div class="features">
										<article>
											<p>
												<ul>
													<li> Medical Image Computing and Computer Assisted Intervention (MICCAI) Young Scientist Award Shortlisted (10 over 1630 papers), 2021 <br /></li>
													<li> Medical Image Computing and Computer Assisted Intervention (MICCAI) Travel Award, 2020, 2021 <br /></li>
													<li> Mind, Brain, Computation and Technology Student Member, Stanford University, 2020 <br /></li>
													<li> School of Engineering Fellowship, Stanford University, 2019 <br /></li>
													<li> International Society for Magnetic Resonance in Medicine (ISMRM) Trainee Stipend Award, 2018 <br /></li>
													<li> IEEE International Joint Conference on Biometrics Best Student Paper Award Runner-Up, 2017 <br /></li>
													<li> Scholarship of Academic Excellence, Tsinghua University, 2016 <br /></li>
													<li> Scholarship of Social Work, Tsinghua University, 2015  <br /></li>
													<li> Scholarship of Voluntary and Public Welfare, Tsinghua University, 2015</li>
												</ul>
											</p>
										</article>
									</div>
								</div>
							</section>

							<section id="five">
								<div class="container">
									<h3>Professional Services</h3>
									<div class="features">
										<article>
											<h4>Journal Review</h4>
											<div class="inner">
												<p>
													<ul>
														<li> NeuroImage <br /></li>
														<li> Medical Image Analysis (MEDIA)   <br /></li>
														<li> IEEE Transactions on Medical Imaging (TMI)   <br /></li>
														<li> Scientific Reports   <br /></li>
														<li> Pattern Recognition   <br /></li>
														<li> Journal of Biomedical and Health Informatics (JBHI)  <br /></li>
														<li> IEEE Transactions on Radiation and Plasma Medical Sciences (TRPMS) <br /></li>
														<li> IEEE Access  <br /></li>
													</ul>
												</p>
											</div>
										</article>
										<article>
											<h4>Conference Review</h4>
											<div class="inner">
												<p>
													<ul>
														<li> European Conference on Computer Vision (ECCV), 2022 <br /></li>
														<li> IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022 <br /></li>
														<li> Medical Image Computing and Computer Assisted Intervention (MICCAI), 2020, 2021, 2022  <br /></li>
														<!-- <li> Medical Imaging with Deep Learning (MIDL), 2021  <br /></li> -->
														<li> IEEE Winter Conference on Applications of Computer Vision (WACV), 2019</li>
													</ul>
												</p>
											</div>
										</article>
									</div>
								</div>
							</section>

							<section id="six">
								<div class="container">
									<h3>Others</h3>
									<div class="features">
										<article>
											<p>
												<ul>
													<li> Mentor of computational biology group, <a href="https://ai-4-all.org/summer-programs/"><font color="#6F9FD8">AI4ALL</font></a>, Summer 2021  <br /></li>
													<li> Medical Image Computing and Computer Assisted Intervention (MICCAI) Student Board, Professional Events Officer, 2021, 2022</li>
												</ul>
											</p>
										</article>
									</div>
								</div>
							</section>

							<section id="seven">
								<div class="container">
									<h3>Fun Facts</h3>
									<div class="features">
										<p> On my spare time, I like cooking, camping, and body-combat! </p>
										<!-- <article>
											<h4>Multi-Modal Analysis</h4>
											<a href="#" class="image" style="width:50%;display:inline-block;"><img src="images/multi-modal.png" alt=""/></a>
											<div class="inner" style="width:50%;display: block;margin:0px 400px;">
												<p>I have a four month old golen retriever puppy named "Danhuang", which means egg yolk in Chinese. <br />On my spare time, I like cooking, camping, and body-combat! </p>
											</div>
										</article> -->
									</div>
								</div>
							</section>


					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
